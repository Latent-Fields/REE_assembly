# Summary

## Source wording
SimSiam reports non-collapsing self-supervised learning via stop-gradient and predictor asymmetry without EMA targets.

## REE translation
This is mixed for MECH-058: anchor timescale separation is a strong option, but not universally required if other asymmetry guardrails exist.

## Mapping caveat
Different optimization/task regimes limit direct transfer to REE shift-robustness claims.
