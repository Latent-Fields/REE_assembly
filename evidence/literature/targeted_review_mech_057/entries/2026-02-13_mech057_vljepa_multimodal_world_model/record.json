{
  "schema_version": "literature_evidence/v1",
  "literature_type": "targeted_review_mech_057",
  "entry_id": "2026-02-13_mech057_vljepa_multimodal_world_model",
  "timestamp_utc": "2026-02-13T20:50:00Z",
  "claim_ids_tested": [
    "MECH-057"
  ],
  "source": {
    "title": "VL-JEPA: Joint Embedding Predictive Architecture for Vision-language",
    "authors": [
      "Delong Chen",
      "Mustafa Shukor",
      "Theo Moutakanni",
      "Willy Chung",
      "Yann LeCun",
      "Pascale Fung"
    ],
    "year": 2025,
    "venue": "arXiv",
    "doi": "10.48550/arXiv.2512.10942",
    "url": "https://arxiv.org/abs/2512.10942"
  },
  "evidence_class": "machine_learning_experiment",
  "evidence_direction": "supports",
  "confidence": 0.65,
  "confidence_rationale": "Supports JEPA extension into vision-language world modeling and selective decoding; strong for substrate breadth, indirect for control-plane necessity.",
  "summary_path": "summary.md",
  "failure_signatures": [],
  "tags": [
    "vl-jepa",
    "vision_language",
    "multimodal",
    "selective_decoding"
  ]
}
