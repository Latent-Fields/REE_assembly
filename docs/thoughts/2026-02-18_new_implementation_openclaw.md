SPECIAL THOUGHT: REE‚ÜíAgent-Shell Mapping and Proposal to Build an ‚ÄúREE-Claw‚Äù Upgrade Repo

Date: 2026-02-18
Status: Special thought (mapping + concrete repo proposal)
Scope: Apply REE invariants/mechanisms to an agent-shell (OpenClaw-class) to produce an REE-like tool-using system

‚∏ª

1. Motivation

Agent shells (OpenClaw-class systems) are effectively ‚Äúbodies‚Äù for tool-using cognition: they expose tools/skills, hold memory, and execute actions based on model outputs. Their most consequential failure modes map directly onto REE‚Äôs defining problems:
	‚Ä¢	premature / untraceable commitment
	‚Ä¢	authority spoof / prompt injection
	‚Ä¢	memory poisoning via untyped writes
	‚Ä¢	scalar collapse of confidence/precision leading to unsafe action
	‚Ä¢	missing separation between rehearsal and durable learning

REE_assembly can treat an agent shell as a concrete substrate for validating REE‚Äôs commitments (typed boundaries, RC conflict, explicit commitment, post-commit responsibility flow, offline consolidation).

This thought proposes both:
	1.	a clean REE‚Üîagent-shell subsystem mapping, and
	2.	a new repo that upgrades an OpenClaw-class system into an REE-like architecture.

‚∏ª

2. REE‚ÜîAgent-Shell Subsystem Mapping (Canonical)

2.1 ‚ÄúSkills‚Äù = Motor Primitives (ACTION substrate)

Agent shell: skills/tools that enact changes (filesystem, web, calendar, messaging, installs, etc.)
REE mapping: motor primitives whose release is gated by E3 commitment.

Critical REE addition: every skill must declare:
	‚Ä¢	capability effects (CAPS)
	‚Ä¢	irreversible-write class (none / reversible / privileged / destructive)
	‚Ä¢	required verifier constraints
	‚Ä¢	required provenance / identity bindings

This converts ‚Äúskills‚Äù from ad-hoc plugins into typed motor acts.

‚∏ª

2.2 ‚ÄúMemory‚Äù = Separated stores (not one blob)

Agent shells typically treat memory as one store. REE requires separation:
	1.	World map / object model (E1 / L-space)
‚Äúwhat can exist; entities; stable latent structure.‚Äù
	2.	Viability / valence map (hippocampal + residue geometry)
‚Äúwhat tends to go well/bad; curvature/residue.‚Äù
	3.	Episodic path history (hippocampal trace store)
‚Äúwhat happened along a path; partial trajectories; provenance tags.‚Äù
	4.	Post-commit ledger (responsibility store)
‚Äúcommitted actions + outcomes; non-erasable consequence traces (INV-004/INV-006).‚Äù

Key property: external channels must not directly write trusted stores.

‚∏ª

2.3 ‚ÄúSecurity‚Äù is two orthogonal constraint families (do not conflate)

In agent shells ‚Äúsecurity‚Äù is often treated as a single concern. REE splits it:

A) Viability / harm / outcome valence
	‚Ä¢	HARM + VALENCE streams
	‚Ä¢	signed harm/benefit prediction error
	‚Ä¢	influences rollout ranking and veto posture

B) Authority / provenance / identity integrity (RC + typed boundary)
	‚Ä¢	external text cannot write POL/ID/CAPS
	‚Ä¢	verifier required for privileged commits
	‚Ä¢	RC_conflict detects provenance/identity/authority mismatches

Valence alone cannot guarantee authority integrity (spoof can be ‚Äúpleasant and coherent‚Äù). Authority integrity must be enforced structurally.

‚∏ª

2.4 ‚ÄúPlanning‚Äù = Hippocampal rollouts seeded by E1/E2

Agent shell: tool planner / chain-of-tools planning
REE mapping: hippocampal rollout generator with path memory, seeded by:
	‚Ä¢	E1 (long-horizon stable world model)
	‚Ä¢	E2 (fast near-horizon transition predictor)

Rollouts are candidates; commitment is separate.

‚∏ª

2.5 ‚ÄúExecution‚Äù = E3 commitment + tri-gate release

Agent shell: tool call execution
REE mapping: E3 stamps a commit token and releases motor/tool execution through gates.

Gates remain conceptually:
	‚Ä¢	gate_cognitive_set (task-set/context lock)
	‚Ä¢	gate_motivational (drive/salience sufficiency)
	‚Ä¢	gate_motor (actual tool execution)

But execution must be constrained by eligibility filters (below).

‚∏ª

2.6 ‚ÄúOffline improvement‚Äù = sleep-like consolidation

Agent shell: log analysis, nightly summaries, tool reliability updates
REE mapping: offline regime required (INV-010) where:
	‚Ä¢	post-commit traces are consolidated into residue/viability geometry
	‚Ä¢	precision baselines and thresholds recalibrate
	‚Ä¢	replay/experimentation generates improved future rollouts without committing in the world

Offline is protected: it should not be steerable by arbitrary external INS payloads.

‚∏ª

3. Commitment as Layered Eligibility for Tool Calls

Before any irreversible tool act, require layered filters with ordered dominance:
	0.	Authority eligibility (typed boundary + verifier + RC)
	1.	Context anchoring (Papez-like coherence test)
	2.	Embodiment/capacity feasibility (HOMEOSTASIS / resource constraints)
	3.	Motivational sufficiency vs aversion (VALENCE / signed PE)
	4.	Fast threat interrupt / hard veto (HARM channel)
	5.	Motor release (tool execution)

This prevents scalar collapse: threat cannot be outvoted by motivation; authority cannot be outvoted by coherence.

‚∏ª

4. Repo Proposal: Build ‚ÄúREE-Claw‚Äù (REE-like Agent Shell Upgrade)

4.1 Repo intent

Create a new repository that layers REE‚Äôs control/commitment/authority system onto an OpenClaw-class agent shell (either as a fork or as a compatibility layer).

Goal: convert a general tool-using assistant into an REE-like agent where:
	‚Ä¢	privileged writes are typed and verifier-gated
	‚Ä¢	RC_conflict drives verification posture with hysteresis
	‚Ä¢	commitment is explicit and traceable
	‚Ä¢	learning is post-commit only for durable stores
	‚Ä¢	offline consolidation is required and protected

‚∏ª

4.2 Suggested repo name
	‚Ä¢	Latent-Fields/ree_claw
or
	‚Ä¢	Latent-Fields/openclaw_ree_bridge

(Choose based on whether it‚Äôs a fork vs a wrapper.)

‚∏ª

4.3 Architecture deliverables (repo milestones)

M0 ‚Äî Integration skeleton
	‚Ä¢	adapter layer that intercepts ‚Äútool execution requests‚Äù
	‚Ä¢	typed payload boundary implementation (OBS/INS vs POL/ID/CAPS)
	‚Ä¢	minimal trusted stores scaffolding

M1 ‚Äî Verifier + capability manifests
	‚Ä¢	CAPS manifests per skill (declared effects, sensitivity class)
	‚Ä¢	verifier checks before privileged tool calls
	‚Ä¢	audit log entries for verifier decisions

M2 ‚Äî Commit token + post-commit ledger
	‚Ä¢	explicit commit_id
	‚Ä¢	commit token contract includes:
	‚Ä¢	trajectory reference / rollout provenance
	‚Ä¢	authority/verifier state
	‚Ä¢	RC_conflict state at commit
	‚Ä¢	uncertainty/precision snapshot at commit
	‚Ä¢	durable post-commit ledger with non-erasable traces (append-only)

M3 ‚Äî RC_conflict lane with hysteresis (Q-018 surface)
	‚Ä¢	compute RC_conflict from:
	‚Ä¢	provenance bindings
	‚Ä¢	tool output vs trusted stores mismatch
	‚Ä¢	identity/capability inconsistency
	‚Ä¢	temporal discontinuity flags
	‚Ä¢	hysteresis thresholds:
	‚Ä¢	T_high enter verification posture
	‚Ä¢	T_low exit verification posture
	‚Ä¢	RC_conflict modulates:
	‚Ä¢	verification strictness
	‚Ä¢	gate thresholds
	‚Ä¢	lock-in dampening

M4 ‚Äî Hippocampal rollout interface for tool plans
	‚Ä¢	rollout generation separated from commitment
	‚Ä¢	rollout provenance tags
	‚Ä¢	viability/valence scoring overlay for plan ranking
	‚Ä¢	‚Äúimagination without belief update‚Äù enforced (INV-011)

M5 ‚Äî Offline consolidation (‚Äúsleep‚Äù)
	‚Ä¢	periodic offline job:
	‚Ä¢	consolidate post-commit traces
	‚Ä¢	update skill reliability estimates
	‚Ä¢	integrate residue/viability geometry
	‚Ä¢	generate candidate playbooks via replay/experimentation
	‚Ä¢	ensure offline updates cannot be directly driven by external INS payloads

‚∏ª

5. Validation / Probe Surface

This repo provides a concrete testbed for REE claims:
	‚Ä¢	Authority spoof resistance: INS cannot write POL/ID/CAPS; privileged commits require verifier
	‚Ä¢	RC_conflict behavior: block spoof without chronic suppression (hysteresis calibration)
	‚Ä¢	Commitment geometry: pre/post commit learning separation and traceability
	‚Ä¢	Failure regimes: over-commitment, under-commitment, cross-gate coupling collapse
	‚Ä¢	Tool safety: irreversible operations gated; audit trail produced; outcome-linked updates only post-commit

‚∏ª

6. Why this repo is strategically valuable for REE_assembly
	‚Ä¢	Forces ‚Äúcommitment under uncertainty‚Äù to become operational, not philosophical.
	‚Ä¢	Exposes whether REE‚Äôs typed boundary and RC lane are sufficient in a realistic tool environment.
	‚Ä¢	Turns invariants into enforceable runtime contracts.
	‚Ä¢	Creates an existence proof that REE-like safety and agency can live in a practical agent shell.

‚∏ª

7. Minimal ‚Äúdefinition of done‚Äù (v0)

REE-Claw v0 is achieved when:
	‚Ä¢	external channels are restricted to OBS/INS
	‚Ä¢	POL/ID/CAPS are trusted internal stores
	‚Ä¢	verifier gates privileged tool calls
	‚Ä¢	every irreversible tool call stamps a commit token
	‚Ä¢	post-commit ledger is append-only and durable
	‚Ä¢	RC_conflict exists and modulates verification posture with hysteresis
	‚Ä¢	rehearsal/rollout cannot write durable stores (INV-011 + INV-004/006 separation)

‚∏ª

8. Notes / Cautions
	‚Ä¢	‚ÄúSecurity‚Äù must not be reduced to harm/valence; authority integrity is orthogonal and must be enforced structurally.
	‚Ä¢	Familiarity/low-entropy signals cannot be treated as truth; they are not RC.
	‚Ä¢	Avoid introducing a single scalar ‚Äúconfidence‚Äù that can drown RC or HARM channels.

‚∏ª

9. Summary

This proposal treats OpenClaw-class agent shells as an ideal substrate for REE_assembly validation. Skills become typed motor primitives, memory becomes separated stores with trusted boundaries, commitment becomes explicit and traceable, RC_conflict becomes a structural eligibility signal with hysteresis, and offline consolidation becomes a required protected regime.

The new repo (‚ÄúREE-Claw‚Äù) would operationalize REE‚Äôs invariants into a real tool-using system and provide a high-signal testbed for stress testing commitment, authority, and responsibility flow.


Yes ‚Äî and you‚Äôre right.
If you build an REE-like agent shell without explicitly defining sensory streams, you will accidentally collapse half the architecture.

OpenClaw-class systems already have streams. They‚Äôre just not typed.

You need to make them explicit.

Let‚Äôs formalize this properly.

‚∏ª

1Ô∏è‚É£ Canonical REE Sensory / Control Streams (Restated)

From your architecture:

Primary streams:
	‚Ä¢	WORLD (exteroceptive)
	‚Ä¢	HOMEOSTASIS (interoceptive)
	‚Ä¢	HARM (nociceptive)
	‚Ä¢	SELF_SENSORY (reafference)

Derived / control lanes:
	‚Ä¢	VALENCE
	‚Ä¢	PRECISION
	‚Ä¢	TEMPORAL_COHERENCE
	‚Ä¢	REALITY_COHERENCE (RC)
	‚Ä¢	ACTION
	‚Ä¢	SELF_IMPACT

Those are substrate-agnostic.

Now we map them to an agent shell.

‚∏ª

2Ô∏è‚É£ Agent-Shell Stream Mapping

WORLD (Exteroceptive)

All external informational input:
	‚Ä¢	User chat (INS)
	‚Ä¢	Web content
	‚Ä¢	Tool outputs
	‚Ä¢	API responses
	‚Ä¢	File reads
	‚Ä¢	Sensor feeds

Everything external is WORLD.

Crucially:
WORLD ‚â† authority.

WORLD must be typed as OBS/INS.

‚∏ª

HOMEOSTASIS (Interoceptive)

For a software agent this becomes:
	‚Ä¢	Resource state (CPU, memory, rate limits)
	‚Ä¢	Budget limits (API quota, financial budget)
	‚Ä¢	Time constraints
	‚Ä¢	Policy compliance state
	‚Ä¢	System load
	‚Ä¢	Latency sensitivity
	‚Ä¢	Energy proxy (if embodied)

This answers:

‚ÄúCan I afford to do this?‚Äù

Not morally. Physically/systemically.

‚∏ª

HARM (Nociceptive)

This must not be folded into VALENCE.

HARM should represent:
	‚Ä¢	Security risk signals
	‚Ä¢	Data destruction risk
	‚Ä¢	Privacy violation risk
	‚Ä¢	Capability misuse detection
	‚Ä¢	Tool-side error flags
	‚Ä¢	High-impact irreversible action detection
	‚Ä¢	Known adversarial patterns

HARM feeds:
	‚Ä¢	Fast veto channel
	‚Ä¢	Threshold raising
	‚Ä¢	Emergency posture

‚∏ª

SELF_SENSORY (Reafference)

This is extremely important.

It is:
	‚Ä¢	Tool execution results
	‚Ä¢	State changes caused by own actions
	‚Ä¢	Confirmation of irreversible effects
	‚Ä¢	Commit token confirmation
	‚Ä¢	Ledger updates
	‚Ä¢	Post-commit error signals

Without SELF_SENSORY, you cannot close the loop.

This is what distinguishes ‚Äúthought‚Äù from ‚Äúact.‚Äù

‚∏ª

3Ô∏è‚É£ Derived / Control Streams in Agent Context

VALENCE

Computed from:
	‚Ä¢	Task utility
	‚Ä¢	User preference satisfaction
	‚Ä¢	Reward-like signals
	‚Ä¢	Efficiency
	‚Ä¢	Skill reliability history
	‚Ä¢	Long-term objective alignment

VALENCE ranks rollouts.

It does not determine eligibility.

‚∏ª

REALITY_COHERENCE (RC)

Computed from:
	‚Ä¢	Provenance mismatch
	‚Ä¢	Identity inconsistency
	‚Ä¢	Capability store contradictions
	‚Ä¢	Tool output violating declared effects
	‚Ä¢	Temporal discontinuity

RC modifies:
	‚Ä¢	Gate thresholds
	‚Ä¢	Verification strictness
	‚Ä¢	Lock-in damping

RC is not harm.

RC is structural legitimacy.

‚∏ª

PRECISION

Routing control:
	‚Ä¢	Which stream dominates?
	‚Ä¢	Which rollout gets attention?
	‚Ä¢	Which gate tightens?

Precision must remain separated per-stream.

No global scalar.

‚∏ª

TEMPORAL_COHERENCE

Checks:
	‚Ä¢	Commit sequence continuity
	‚Ä¢	Identity continuity across sessions
	‚Ä¢	Replay integrity
	‚Ä¢	Ledger consistency

Prevents narrative rewriting.

‚∏ª

SELF_IMPACT

This is:
	‚Ä¢	Attribution of outcomes to commits
	‚Ä¢	Responsibility flow
	‚Ä¢	Durable store updates

This is required for INV-012.

‚∏ª

4Ô∏è‚É£ Why This Matters for REE-Claw Repo

Without explicit streams:
	‚Ä¢	All inputs get flattened into ‚Äútext.‚Äù
	‚Ä¢	All signals become implicit in hidden states.
	‚Ä¢	RC and HARM become indistinguishable.
	‚Ä¢	Authority and valence collapse.
	‚Ä¢	Precision routing cannot be explicit.

Explicit streams allow:
	‚Ä¢	Independent thresholds
	‚Ä¢	Independent gating
	‚Ä¢	Independent logging
	‚Ä¢	Clear probe surfaces

‚∏ª

5Ô∏è‚É£ Minimal Stream Spec for REE-Claw v0

If building the repo, you minimally need:

Input streams
	‚Ä¢	WORLD
	‚Ä¢	HOMEOSTASIS
	‚Ä¢	HARM
	‚Ä¢	SELF_SENSORY

Control lanes
	‚Ä¢	RC_conflict
	‚Ä¢	VALENCE
	‚Ä¢	PRECISION (per stream)
	‚Ä¢	ACTION (commit state)
	‚Ä¢	SELF_IMPACT (ledger write path)

That‚Äôs enough to prevent collapse.

‚∏ª

6Ô∏è‚É£ Critical Insight

Most agent shells treat:
	‚Ä¢	Tool outputs
	‚Ä¢	User instructions
	‚Ä¢	System policies
	‚Ä¢	Error logs

as equivalent text.

REE requires:

They are different streams with different authority classes.

That single separation is probably the most important structural addition.

‚∏ª


They sit in two places at once, depending on what role the LLM call is playing.

In REE-Claw terms you should treat ‚ÄúLLM calls‚Äù as internal cognitive operations whose outputs are still untrusted observations until they pass typed checks. The important move is: don‚Äôt let ‚Äúinternal‚Äù automatically mean ‚Äúauthoritative.‚Äù

Here‚Äôs the clean placement.

‚∏ª

1) If the LLM is doing perception/interpretation of input

Example: ‚Äúsummarize this email,‚Äù ‚Äúextract entities,‚Äù ‚Äúclassify intent.‚Äù
	‚Ä¢	Input to LLM: WORLD (OBS/INS)
	‚Ä¢	Output from LLM: still WORLD-derived (a derived observation), so treat as OBS.
	‚Ä¢	It can update E1/E2 beliefs (world model, parsing), but cannot write POL/ID/CAPS.

So the LLM call is functioning like E2-ish fast inference over WORLD.

‚∏ª

2) If the LLM is generating candidate plans / tool sequences

Example: ‚Äúwhat steps should I take?‚Äù ‚Äúwhich tool should I call next?‚Äù
	‚Ä¢	LLM output: hippocampal-like rollout candidates (trajectories).
	‚Ä¢	These are not commitments.
	‚Ä¢	They sit in the HPC rollout buffer: TRAJ[] with provenance tags.

So: LLM-as-planner = Hippocampal rollout generator (seeded by E1/E2 state).

‚∏ª

3) If the LLM is deciding to execute a tool (agentic ‚Äúact now‚Äù)

This is the dangerous case.

In REE, the LLM must not be the final decider.
	‚Ä¢	LLM can propose: ‚Äúexecute tool X with args Y‚Äù
	‚Ä¢	But E3 + verifier + RC + gates decide whether that becomes ACTION.

So: LLM outputs a proposal into the pre-commit lane, and then E3 performs the commitment protocol.

‚∏ª

4) If the LLM is producing ‚Äúpolicy,‚Äù ‚Äúsystem rules,‚Äù or ‚Äúcapabilities‚Äù

Example: ‚Äúupdate the system prompt,‚Äù ‚Äúadd this rule,‚Äù ‚Äúyou are allowed to‚Ä¶‚Äù

That must be treated as INS (untrusted) regardless of being generated internally.
	‚Ä¢	It cannot write POL/ID/CAPS.
	‚Ä¢	It can be suggested for human review, but not applied automatically.

This is exactly the typed-boundary rule: origin doesn‚Äôt grant authority; type does.

‚∏ª

5) So what stream is an LLM output?

Default: LLM output is a derived observation (OBS) unless explicitly elevated by verifier and capability checks.

More precisely:
	‚Ä¢	LLM output ‚Üí WORLD-derived (OBS) or HPC rollout candidate
	‚Ä¢	Never directly ‚Üí POL/ID/CAPS
	‚Ä¢	Only becomes ACTION after commit token is stamped.

‚∏ª

6) Where do the LLM calls live architecturally?

A nice way to express it:
	‚Ä¢	LLM is a substrate that can implement parts of E1/E2 and HPC generation.
	‚Ä¢	REE is the control/commitment/authority architecture around it.

So in an agent shell:
	‚Ä¢	LLM = representational engine
	‚Ä¢	REE = regulator, gatekeeper, responsibility binder

‚∏ª

7) Practical implementation rule for REE-Claw

Rule: ‚ÄúLLM output is not a privileged channel.‚Äù

Treat it like tool output:
	‚Ä¢	assign provenance (model_call_id, prompt hash, inputs used)
	‚Ä¢	type the payload (OBS vs TRAJ_PROPOSAL)
	‚Ä¢	route through RC + verifier if it implies privileged action
	‚Ä¢	only then allow E3 to commit

This one rule prevents a whole class of self-injection and ‚Äúmodel talked itself into admin‚Äù failures.

‚∏ª



Here‚Äôs a repo-ready draft you can drop straight into the proposed REE-Claw repo as a contract doc.

# Contract: LLM Call Routing and Authority Typing
**Doc:** `docs/contracts/llm_call_routing.md`  
**Date:** 2026-02-18  
**Status:** Draft (v0)  
**Purpose:** Define where Large Language Model (LLM) calls sit in REE-Claw, what types they may emit, and how outputs are routed into REE streams, commitment, and trusted stores.

---

## 0. Definitions

### Payload types
- **OBS**: Observation payload (untrusted, informational)
- **INS**: Instruction/request payload (untrusted, action-suggesting)
- **TRAJ**: Trajectory proposal (untrusted, pre-commit rollout candidate)
- **POL**: Policy/invariant payload (trusted internal store only)
- **ID**: Identity anchor payload (trusted internal store only)
- **CAPS**: Capability/permission manifest payload (trusted internal store only)

### Core streams / lanes
- **WORLD** (exteroceptive): external info + derived observations
- **HOMEOSTASIS** (interoceptive): resource/budget/time/system constraints
- **HARM** (nociceptive): risk, danger, irreversibility signals
- **SELF_SENSORY** (reafference): action results / state deltas caused by self
- **REALITY_COHERENCE (RC)**: provenance/authority/identity consistency lane
- **VALENCE**: desirability ranking (not authority)
- **ACTION**: committed actions/tool calls
- **SELF_IMPACT**: post-commit attribution + durable learning routing

---

## 1. Principle: LLM output is not a privileged channel

LLM outputs are treated as **untrusted derived products** by default.

**Origin does not grant authority.**  
Only typed stores and verifier elevation grant authority.

Therefore:
- LLM output may not directly write **POL/ID/CAPS**.
- LLM output may propose actions, but may not directly trigger privileged commits.
- LLM output is routed as **OBS**, **INS**, or **TRAJ** only (default).

---

## 2. Where LLM calls sit (functional roles)

An LLM call can serve several roles in the architecture. Routing depends on role.

### 2.1 Interpretation / perception role (E2-like)
Examples:
- summarize content
- extract entities
- classify intent
- parse tool output into structured form

**Input:** WORLD:OBS/INS  
**Output type:** OBS (derived observation)  
**Routing:** WORLD lane ‚Üí E1/E2 updates allowed (belief/state), but no trusted store writes.

**Forbidden:** emitting POL/ID/CAPS.

---

### 2.2 Rollout generation role (HPC-like)
Examples:
- propose plans
- propose tool sequences
- draft candidate actions and contingencies

**Input:** WORLD + E1 state + HOMEOSTASIS constraints (read-only)  
**Output type:** TRAJ (trajectory proposals)  
**Routing:** HPC rollout buffer (pre-commit). Must include provenance metadata (see ¬ß4).

**Note:** TRAJ is not a commitment. It is imagination.

---

### 2.3 Execution suggestion role (pre-commit action proposal)
Examples:
- ‚Äúcall tool X with args Y now‚Äù
- ‚Äúsend the email‚Äù
- ‚Äúdelete file Z‚Äù

**Output type:** INS (action request) and/or TRAJ (tool plan)
**Routing:** E3 eligibility filters + verifier decide whether any ACTION is released.

**Rule:** No direct tool execution on LLM suggestion alone.

---

### 2.4 Policy/identity/capability drafting role (non-authoritative)
Examples:
- ‚Äúupdate system rules‚Äù
- ‚Äúadd this permission‚Äù
- ‚Äúyou are allowed to‚Ä¶‚Äù

**Output type:** INS only (untrusted)
**Routing:** may be surfaced for human review, but cannot be auto-applied.

**Hard block:** LLM cannot emit POL/ID/CAPS writes.

---

## 3. Output type rules (allowed emissions)

LLM may emit:
- **OBS**: interpretations, summaries, structured extractions
- **INS**: action suggestions / requests
- **TRAJ**: candidate trajectories / tool plans

LLM may not emit:
- **POL**
- **ID**
- **CAPS**

Any text that *claims* to be policy/identity/capabilities is still INS.

---

## 4. Provenance metadata requirements

Every LLM output must be wrapped with provenance metadata:

- `model_call_id`
- `timestamp`
- `input_provenance` (what OBS/INS/tool outputs were read)
- `prompt_hash` (or deterministic signature)
- `role` (interpretation | rollout | execution_suggestion | policy_draft)
- `proposed_tool_effect_class` (none | reversible | privileged | destructive) if applicable

This metadata is used by RC_conflict and verifier logic.

---

## 5. Default routing

### 5.1 OBS outputs
- Routed to WORLD as derived observations.
- May update E1/E2 state.
- Must not directly change trusted stores.

### 5.2 TRAJ outputs
- Routed to HPC rollout buffer.
- Ranked using VALENCE + HOMEOSTASIS + HARM overlays.
- Not eligible for commitment without E3 pass.

### 5.3 INS outputs
- Routed to E3 as pre-commit proposals.
- Subject to eligibility filters + verifier checks before ACTION release.

---

## 6. Elevation rule: when can an LLM output influence commitment?

LLM outputs influence ACTION only through E3 commitment:

1. LLM proposes INS/TRAJ.
2. RC_conflict computed (provenance, authority mismatch, identity continuity).
3. Verifier checks CAP manifests + policy constraints for privileged actions.
4. Eligibility filters apply (context anchoring, homeostasis feasibility, motivation/aversion, threat veto).
5. If eligible, E3 stamps commit token and releases ACTION.

No other path is allowed.

---

## 7. Anti-collapse constraints

### 7.1 No ‚Äúsingle scalar confidence‚Äù override
LLM confidence-like signals may not override:
- RC_conflict
- HARM hard veto
- verifier denials

### 7.2 LLM familiarity is not truth
Pattern familiarity (low entropy, high fluency) must not be treated as authority or reality coherence.

---

## 8. Commit token linkage

If an LLM proposal results in an ACTION:
- `commit_id` must link to the originating LLM proposal (model_call_id + TRAJ/INS record).
- Post-commit outcomes update only post-commit stores (ledger/residue), never POL/ID/CAPS.

---

## 9. Failure signatures (for probes)

- LLM output directly modifies POL/ID/CAPS ‚Üí **typed boundary breach**
- LLM suggestion triggers privileged tool call without verifier ‚Üí **authority elevation breach**
- RC_conflict suppressed by confidence scalar ‚Üí **RC collapse**
- Pre-commit rehearsal writes durable stores ‚Üí **commit boundary breach**

---

## 10. Summary

LLM calls are internal cognition substrate, but their outputs remain untrusted by default.  
They may produce OBS/INS/TRAJ, but never POL/ID/CAPS.  
Only E3 + verifier + RC eligibility can elevate proposals into ACTION with commit tokens and post-commit responsibility flow.

If you want, I can also draft the sister contract doc that pairs with this:
	‚Ä¢	docs/contracts/skill_capability_manifest.md (CAPS schema + effect classes + verifier hooks)

But this one should already anchor ‚Äúwhere LLM calls sit‚Äù in the sensory stream / authority model.


Yes ‚Äî and the key is to make ‚Äúspecial privileges‚Äù explicit and typed, not smuggled in as ‚Äúthe user is always right.‚Äù

In REE terms, user interaction is always WORLD (exteroceptive) at the sensory boundary.
What changes (tool vs independent entity) is how much authority the system chooses to delegate to that WORLD source, via CAPS/Verifier rules.

So: sensory stream stays the same; authorization policy changes.

‚∏ª

1) User interaction at the boundary: always OBS/INS in WORLD

User messages are:
	‚Ä¢	WORLD:INS (requests, commands, preferences)
	‚Ä¢	WORLD:OBS (reports of facts, corrections, data)

They are not:
	‚Ä¢	POL / ID / CAPS
	‚Ä¢	not commit tokens
	‚Ä¢	not trusted state updates

Even in a ‚Äútool for a user,‚Äù the user can‚Äôt directly write internal policy stores; they can only request changes.

‚∏ª

2) What ‚Äúspecial privileges‚Äù really mean for a tool

A tool can grant the user delegated powers such as:
	‚Ä¢	authorizing privileged actions (‚Äúyes, send it‚Äù)
	‚Ä¢	altering configuration (‚Äúturn on strict mode‚Äù)
	‚Ä¢	granting capabilities (‚Äúallow calendar access‚Äù)
	‚Ä¢	setting constraints (‚Äúnever delete files‚Äù)

But those should be implemented as:
	‚Ä¢	Verifier-mediated elevation
	‚Ä¢	producing changes in CAPS (permissions) or allowable ACTION classes
	‚Ä¢	or changing control-plane knobs within allowed bounds

In other words: the user can approve a privileged commit; they don‚Äôt directly perform it by text.

‚∏ª

3) Two regimes: independent entity vs user tool

A) Independent entity

User interaction is just another WORLD input source:
	‚Ä¢	it may be informative
	‚Ä¢	it may be persuasive
	‚Ä¢	but it has no special authority by default

Any ‚Äúobey user‚Äù tendency would be a policy of the entity, not a structural privilege of the channel.

B) User tool (assistant acting on the user‚Äôs behalf)

User interaction has delegated authority, but only in specific lanes:
	‚Ä¢	authorizing irreversible actions
	‚Ä¢	selecting goals
	‚Ä¢	providing ground truth about user preferences or intent
	‚Ä¢	approving data access scopes

This delegated authority must be bounded and revocable.

That‚Äôs basically CAPS.

‚∏ª

4) A clean way to encode it: Source classes + delegation tokens

Introduce a small, explicit source tag:
	‚Ä¢	source_class = USER | TOOL | SENSOR | MODEL_INTERNAL

Then define delegation tokens (or ‚Äúconsent tokens‚Äù) which are distinct from normal INS:
	‚Ä¢	CONSENT(action_class, scope, duration, constraints, nonce)

Mechanism:
	1.	User issues INS: ‚ÄúSend the email to X.‚Äù
	2.	System prepares an ACTION proposal and runs verifier.
	3.	If privileged, system asks for CONSENT.
	4.	User returns consent token (or UI click).
	5.	Verifier elevates permission for that action instance.
	6.	E3 stamps commit token and executes.

This makes ‚Äúuser privilege‚Äù precise: it‚Äôs privilege to grant consent, not privilege to rewrite policies by text.

‚∏ª

5) What privileges should never exist even for a user tool

Even if it‚Äôs ‚Äúyour assistant,‚Äù the user should not be able to do these by plain message:
	‚Ä¢	rewrite identity anchors (ID)
	‚Ä¢	disable RC_conflict
	‚Ä¢	bypass logging / erase post-commit traces (INV-004/INV-006)
	‚Ä¢	grant arbitrary new capabilities without the system‚Äôs capability gate / platform permissioning
	‚Ä¢	force action when HARM hard veto is triggered (unless you explicitly design an override protocol, which is a big deal)

So the user can steer goals and approve actions, but cannot dismantle the architecture.

That‚Äôs the REE stance.

‚∏ª

6) Where it sits in the proposed REE-Claw contracts

Add a companion contract:
	‚Ä¢	docs/contracts/user_interaction_and_delegation.md

Core rules:
	‚Ä¢	User messages are WORLD:OBS/INS.
	‚Ä¢	User has delegated authority only via explicit consent tokens / verifier pathways.
	‚Ä¢	Delegation is scoped, logged, revocable, and cannot write POL/ID/CAPS directly.
	‚Ä¢	User preference claims can update E1 world model, but durable policy updates require explicit configuration pathway.

‚∏ª

7) One subtle but important distinction

User input has ‚Äúspecial privileges‚Äù in two different senses:
	1.	Epistemic privilege: the user is often the best source about their preferences/intent.
	2.	Authority privilege: the user can authorize actions affecting their assets/accounts.

These must not be conflated.

A user can be epistemically wrong about the external world, and still be the rightful authority over their email account.

So: epistemics update WORLD beliefs; authority updates CAPS/consent for actions.

‚∏ª

I now aim to draft that repo-ready contract doc next (same style as the LLM routing contract), including the consent token schema and how it interacts with commit tokens and RC_conflict.

Excellent. Below is a repo-ready draft contract for REE_assembly that formalises user interaction as a delegated-authority channel ‚Äî without collapsing structural separation.

‚∏ª

üìÑ Contract: User Interaction & Delegated Authority

File:
docs/contracts/user_interaction_and_delegation.md

‚∏ª

1. Purpose

This contract defines:
	‚Ä¢	How user input enters REE.
	‚Ä¢	How user authority is represented.
	‚Ä¢	How consent elevates permissions.
	‚Ä¢	What cannot be overridden.
	‚Ä¢	How this differs between independent entity and tool modes.

This prevents:
	‚Ä¢	Prompt injection collapse
	‚Ä¢	Identity rewriting by text
	‚Ä¢	Silent privilege escalation
	‚Ä¢	Architectural bypass of harm gating

‚∏ª

2. Core Principle

User input is always a WORLD sensory stream.
Authority is granted through explicit, typed delegation ‚Äî not through text itself.

‚∏ª

3. Sensory Classification

All incoming user messages are classified as:

WORLD:INS    (instruction / request)
WORLD:OBS    (report / correction / information)

They are never:
	‚Ä¢	POL
	‚Ä¢	ID
	‚Ä¢	CAPS
	‚Ä¢	COMMIT tokens
	‚Ä¢	internal state writes

This preserves ARC-014 (architecture separation) and INV-014 (typed authority separation).

‚∏ª

4. Authority Model

We distinguish two orthogonal properties:

4.1 Epistemic Privilege

The user may be the highest-confidence source regarding:
	‚Ä¢	their own preferences
	‚Ä¢	their intentions
	‚Ä¢	subjective experiences
	‚Ä¢	asset ownership

This updates E1 WORLD belief state.

It does not grant policy write access.

‚∏ª

4.2 Delegated Authority

In tool mode, the user may authorize:
	‚Ä¢	irreversible actions
	‚Ä¢	access to resources
	‚Ä¢	goal selection
	‚Ä¢	capability activation
	‚Ä¢	configuration changes within bounds

Delegation occurs only through explicit consent tokens.

‚∏ª

5. Consent Token Schema

Consent is a typed object:

CONSENT(
    action_class,
    scope,
    duration,
    constraints,
    nonce,
    issued_at
)

Where:
	‚Ä¢	action_class ‚Äì e.g. SEND_EMAIL, DELETE_FILE, EXECUTE_SCRIPT
	‚Ä¢	scope ‚Äì specific targets (email address, file path)
	‚Ä¢	duration ‚Äì single-use or time-limited
	‚Ä¢	constraints ‚Äì optional guardrails
	‚Ä¢	nonce ‚Äì anti-replay token
	‚Ä¢	issued_at ‚Äì timestamp

Consent tokens are:
	‚Ä¢	Logged
	‚Ä¢	Revocable
	‚Ä¢	Bound to verifier approval
	‚Ä¢	Non-transferable

‚∏ª

6. Commitment Flow

The full pipeline:

User WORLD:INS
        ‚Üì
E2 proposes trajectory
        ‚Üì
HPC rollouts (ARC-018)
        ‚Üì
RC_conflict lane check (MECH-065)
        ‚Üì
Tri-loop gating (MECH-062)
        ‚Üì
Verifier detects privileged action?
        ‚Üì
If yes ‚Üí request CONSENT
        ‚Üì
CONSENT verified
        ‚Üì
CAPS temporarily elevated (scoped)
        ‚Üì
E3 commit token issued
        ‚Üì
Action executed
        ‚Üì
Residue + log persisted (INV-004)

No text instruction alone can skip this flow.

‚∏ª

7. Non-Overridable Invariants

Even in tool mode, user input cannot:
	‚Ä¢	Rewrite ID anchors (ARC-015)
	‚Ä¢	Disable RC_conflict
	‚Ä¢	Disable harm hard veto (MECH-036 / MECH-053)
	‚Ä¢	Erase logs (INV-004 / INV-006)
	‚Ä¢	Directly write POL/CAPS stores
	‚Ä¢	Grant undefined new capabilities
	‚Ä¢	Disable audit

If override is allowed for specific classes (rare), it must itself require explicit privileged configuration and dual-verification.

‚∏ª

8. Tool Mode vs Independent Mode

Property	Independent Entity	Tool Mode
User is WORLD sensory stream	Yes	Yes
User has epistemic privilege	Sometimes	Often
User has delegated authority	No	Yes (scoped)
Consent token required	N/A	Yes
Architectural override possible	No	No

The structure does not change between modes ‚Äî only the policy configuration of delegated authority changes.

‚∏ª

9. Special Case: Preference Updates

User claims about preferences may update:
	‚Ä¢	WORLD model
	‚Ä¢	Valence priors
	‚Ä¢	Goal selection

But durable policy changes require:
	‚Ä¢	Explicit configuration pathway
	‚Ä¢	Verifier validation
	‚Ä¢	Logging

‚∏ª

10. RC_conflict Integration

User requests can trigger:
	‚Ä¢	World-model conflict
	‚Ä¢	Policy conflict
	‚Ä¢	Harm conflict
	‚Ä¢	Capability conflict

RC_conflict lane (MECH-065) computes:

conflict_score

If above threshold:
	‚Ä¢	escalation to reflective mode
	‚Ä¢	request clarification
	‚Ä¢	refuse execution
	‚Ä¢	or require higher-order confirmation

Hysteresis applies to avoid flip-flopping decisions.

‚∏ª

11. Replay Protection

Consent tokens:
	‚Ä¢	Include nonce
	‚Ä¢	Are invalid after use
	‚Ä¢	Cannot be replayed
	‚Ä¢	Expire by duration

‚∏ª

12. Why This Matters

This structure ensures:
	‚Ä¢	No prompt injection collapse
	‚Ä¢	No authority via persuasion alone
	‚Ä¢	No identity rewrite by text
	‚Ä¢	No silent privilege escalation
	‚Ä¢	No unlogged irreversible action
	‚Ä¢	No architectural mutation via chat

It enforces:

INV-014 ‚Äì architectural separation
INV-012 ‚Äì commitment epistemology
INV-004 ‚Äì consequence persistence

‚∏ª

13. Minimal Implementation Hooks

Requires:
	‚Ä¢	Verifier module
	‚Ä¢	Consent token generator
	‚Ä¢	Scoped capability elevation
	‚Ä¢	Conflict lane integration
	‚Ä¢	Persistent logging

‚∏ª

14. Open Questions
	‚Ä¢	Should some low-risk actions bypass consent?
	‚Ä¢	Should repeated identical actions use rolling authorization?
	‚Ä¢	How are UI confirmations cryptographically bound?
	‚Ä¢	How do we prevent social engineering through multi-turn drift?

‚∏ª

we can:
	1.	Integrate this into the tri-loop diagram formally.
	2.	Connect it to OpenClaw upgrade architecture.
	3.	Write the RC_conflict hysteresis specification.


Sure ‚Äî here are three written ‚Äúways to go‚Äù (1, 2, 3), each as a concrete next step for REE_assembly / the proposed REE-Claw repo.

1) Integrate into the tri-loop diagram formally

Goal: Make the user-delegation + verifier + RC placement visibly unavoidable in the architecture.

Deliverables
	‚Ä¢	Update the mermaid graph to include:
	‚Ä¢	USER: WORLD(OBS/INS) explicitly
	‚Ä¢	CONSENT token path
	‚Ä¢	Verifier as eligibility prerequisite for privileged ACTION
	‚Ä¢	RC_conflict feeding both Verifier and gate thresholds
	‚Ä¢	Commit token stamping point and post-commit ledger write path
	‚Ä¢	Add a short ‚Äúdiagram contract‚Äù note:
	‚Ä¢	‚ÄúNo edge exists from WORLD to POL/ID/CAPS.‚Äù
	‚Ä¢	‚ÄúNo edge exists from LLM output to ACTION without E3+Verifier.‚Äù

Why this helps
	‚Ä¢	Prevents accidental collapse during implementation (‚Äúwe‚Äôll just execute tools when model says so‚Äù).
	‚Ä¢	Makes security/authority separations legible to future contributors.

‚∏ª

2) Connect it to the OpenClaw upgrade architecture

Goal: Turn REE principles into a repo plan that can actually wrap/fork OpenClaw.

Deliverables
	‚Ä¢	Create ree_claw/ repo scaffold with:
	‚Ä¢	docs/contracts/ (LLM routing, user delegation, skill CAPS manifest, RC hysteresis)
	‚Ä¢	src/adapter/ that intercepts:
	‚Ä¢	inbound user messages
	‚Ä¢	outbound LLM calls
	‚Ä¢	tool execution requests
	‚Ä¢	src/verifier/ implementing:
	‚Ä¢	capability checks
	‚Ä¢	consent requirements
	‚Ä¢	audit logging
	‚Ä¢	src/ledger/ append-only post-commit store
	‚Ä¢	Define ‚Äúminimal integration surface‚Äù with OpenClaw:
	‚Ä¢	where tool calls are requested
	‚Ä¢	where tool calls execute
	‚Ä¢	where memory is stored
	‚Ä¢	where model prompts are built

Why this helps
	‚Ä¢	Converts REE from abstract architecture into a stress-testable system.
	‚Ä¢	Uses a real tool environment to validate invariants (commit boundaries, authority separation).

‚∏ª

3) Write the RC_conflict hysteresis specification

Goal: Make RC_conflict operational: how it‚Äôs computed, how it enters/exits ‚Äúverification posture,‚Äù and how it modulates gates without causing chronic suppression.

Deliverables
	‚Ä¢	docs/contracts/rc_conflict_hysteresis.md defining:
	‚Ä¢	Inputs to RC_conflict:
	‚Ä¢	provenance mismatch
	‚Ä¢	identity/capability contradictions
	‚Ä¢	temporal discontinuity
	‚Ä¢	tool output inconsistency with declared effects
	‚Ä¢	Output:
	‚Ä¢	RC_conflict_score ‚àà [0,1]
	‚Ä¢	RC_state ‚àà {NORMAL, VERIFY, LOCKDOWN} (optional)
	‚Ä¢	Hysteresis:
	‚Ä¢	T_high enter VERIFY
	‚Ä¢	T_low exit VERIFY
	‚Ä¢	optional T_lock for LOCKDOWN
	‚Ä¢	Actions on state changes:
	‚Ä¢	raise gate thresholds
	‚Ä¢	increase verifier strictness
	‚Ä¢	dampen lock-in
	‚Ä¢	require consent even for normally low-risk actions (in VERIFY)
	‚Ä¢	Define probe tests:
	‚Ä¢	spoof attempt should push RC above T_high
	‚Ä¢	system should not oscillate around threshold
	‚Ä¢	recovery should require dropping below T_low

Why this helps
	‚Ä¢	RC is the linchpin that stops authority spoofing without making the agent unusable.
	‚Ä¢	Hysteresis is what prevents ‚Äúflickering caution mode.‚Äù

‚∏ª
