# Agency and Responsibility Flow

**Claim Type:** architectural_commitment  
**Scope:** Agency, self-impact attribution, and responsibility flow  
**Depends On:** INV-018 (agency required), INV-012 (commitment gates responsibility), ARC-003 (E3), ARC-005 (control plane), ARC-004 (L-space), ARC-013 (residue geometry), ARC-007 (hippocampal systems)  
**Status:** provisional  
**Claim ID:** ARC-015
<a id="arc-015"></a>

---

Source: `docs/thoughts/2026-02-08_control_plane_modes_responsibility_flow.md`

## Agency and self-impact attribution

REE must support self-impact attribution: the ability to model which parts of incoming data were caused by the agent’s own outputs (efference copy / reafference), and to route that attribution into control-plane learning.

**Subsystem abstract (core claims):** ARC‑015 anchors agency/responsibility flow, while MECH‑023 and MECH‑024 frame
responsibility as path‑dependent geometry and the convergence of selfhood/personality/ethics. Supporting context includes
INV‑018 (agency required), INV‑012 (commitment gates responsibility), ARC‑003 (E3), ARC‑005 (control plane), ARC‑004
(L‑space), ARC‑013 (residue geometry), ARC‑007 (hippocampal systems), and Q‑006 (developmental ethics).

Without it:
- the system can still predict,
- it can even act,
- but responsibility cannot arise internally.

Learning would be about correlation, not ownership.

Responsibility requires the system to know, in a meaningful sense: *this change was because of me*.

## Why motor / policy systems are ethically central

Motor systems are not important because they move bodies. They are important because they instantiate **intervention capacity**.

The moment a system can:
- issue an output,
- predict its sensory consequences (via a fast loop),
- compare predicted versus observed reafference,
- and adjust future control policies,

it acquires:
- ownership of consequences (“this change was mine”),
- counterfactual sensitivity (“if I did otherwise, the world would differ”),
- morally shaped learning (“some interventions are constrained”).

This creates an internal responsibility flow. Responsibility attaches where action meets prediction error.

---

<a id="mech-023"></a>
## Responsibility as geometry, not choice (MECH-023)

Responsibility should not be located at a moment of discrete choice. It lives in the evolving geometry of possible futures.

Control-plane tuning and learning progressively:
- preserve some ethical degrees of freedom,
- collapse others,
- and shape what becomes thinkable, doable, or tolerable.

Two agents in the same state may differ morally because of how they arrived there. Responsibility is therefore path-dependent, history-bound, and non-Markovian.

---

<a id="mech-024"></a>
## Convergence of selfhood, personality, and ethics (MECH-024)

Selfhood, personality, relational identity, and ethics may not be separable modules.

- Selfhood corresponds to stable patterns of control sensitivity.
- Personality reflects long-run biases in tuning and learning.
- Relational identity reflects which others are included in error ownership.
- Ethics reflects which constraints are treated as inviolable.

Responsibility is a global property of this evolved control geometry, not a local rule.

---

## Open Questions

<a id="q-006"></a>
### Q-006: Is ethics developmental rather than additive?

If REE can be refined using human-style cognition — with fast and slow predictors, hippocampal hypothesis injection, and a control plane that governs committed learning — and if systems “brought up well” under these constraints reliably tend toward ethical behaviour, then this would suggest that ethics is developmental rather than additive.

## Related Claims (IDs)

- ARC-015
- MECH-023
- MECH-024
- INV-018
- INV-012
- ARC-003
- ARC-005
- ARC-013
- ARC-007
- Q-006

## References / Source Fragments

- `docs/thoughts/2026-02-08_control_plane_modes_responsibility_flow.md`
